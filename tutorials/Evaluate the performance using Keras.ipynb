{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Evaluate the performance using Keras\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " There are 3 ways to estimate the performance of your models in Python using the Keras library:\n",
    "\n",
    "[1] Automatically splitting a training dataset into train and validation datasets. \n",
    "[2] Manually and explicitly defining a training and validation dataset.\n",
    "[3] Evaluating performance using k-fold cross validation, the gold standard technique.\n",
    "\n",
    "Reference: Deep learning with python, Jason Brownlee\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Automatic Verification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"../DATASETS/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer = \"uniform\" , activation= \"relu\"))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation= \"relu\"))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\" , activation= \"sigmoid\"))\n",
    "\n",
    "# Compile model\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss = bce , optimizer = adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Manual Verification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keras also allows you to manually specify the dataset to use for validation during training.\n",
    "In this example we use the handy train test split() function from the Python scikit-learn\n",
    "machine learning library to separate our data into a training and test dataset. We use 67% \n",
    "for training and the remaining 33% of the data for validation. The validation dataset can be\n",
    "specified to the fit() function in Keras by the validation data argument.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer = \"uniform\" , activation= \"sigmoid\" ))\n",
    "\n",
    "# Compile model\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss = bce , optimizer = adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs = 150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cross validation IS OFTEN NOT USED for evaluating deep learning models because of the greater computational expense.\n",
    "For example k-fold cross validation is often used with 5 or 10 folds. As such, 5 or 10 models must be constructed \n",
    "and evaluated, greatly adding to the evaluation time of a model. Nevertheless, when the problem is small enough or \n",
    "if you have sufficient compute resources, k-fold cross validation can give you a less biased estimate of the \n",
    "performance of your model.\n",
    "\n",
    "The folds are stratified, meaning that the algorithm attempts to balance the number of instances of each class in\n",
    "each fold. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "    model.add(Dense(8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "    model.add(Dense(1, kernel_initializer = \"uniform\" , activation= \"sigmoid\" ))\n",
    "    \n",
    "    # Compile model\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    adam = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss = bce , optimizer = adam, metrics=[\"accuracy\"])\n",
    "   \n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "- https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
