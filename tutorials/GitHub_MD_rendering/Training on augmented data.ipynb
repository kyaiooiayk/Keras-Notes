{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "obvious-frost",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-madness",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Training on augmented data\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-marriage",
   "metadata": {},
   "source": [
    "# Theoretical recall - data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-thumbnail",
   "metadata": {
    "papermill": {
     "duration": 0.00701,
     "end_time": "2021-06-03T16:40:44.246498",
     "exception": false,
     "start_time": "2021-06-03T16:40:44.239488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "- The best way to improve the performance of a machine learning model is to train it on more data. \n",
    "- The more examples the model has to learn from, the better it will be able to recognize which differences in images matter and which do not. \n",
    "- More data helps the model to *generalize* better.\n",
    "- One easy way of getting more data is to use the data you already have. \n",
    "- If we can transform the images in our dataset in ways that preserve the class, we can teach our classifier to ignore those kinds of transformations. \n",
    "- For instance, whether a car is facing left or right in a photo doesn't change the fact that it is a *Car* and not a *Truck*. \n",
    "- So, if we **augment** our training data with flipped images, our classifier will learn that \"left or right\" is a difference it should ignore.\n",
    "- And that's the whole idea behind data augmentation: add in some extra fake data that looks reasonably like the real data and your classifier will improve.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-absence",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "def set_seed(seed = 31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-shock",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-bonus",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-03T16:40:44.267020Z",
     "iopub.status.busy": "2021-06-03T16:40:44.265158Z",
     "iopub.status.idle": "2021-06-03T16:40:54.575965Z",
     "shell.execute_reply": "2021-06-03T16:40:54.576525Z"
    },
    "papermill": {
     "duration": 10.323158,
     "end_time": "2021-06-03T16:40:54.576847",
     "exception": false,
     "start_time": "2021-06-03T16:40:44.253689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../DATASETS/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../DATASETS/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-ratio",
   "metadata": {
    "papermill": {
     "duration": 0.007563,
     "end_time": "2021-06-03T16:40:54.593003",
     "exception": false,
     "start_time": "2021-06-03T16:40:54.585440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building the model with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-pregnancy",
   "metadata": {},
   "source": [
    "\n",
    "- Keras lets you augment your data in two ways. \n",
    "- The first way is to include it in the data pipeline with a function like ImageDataGenerator. The second way is to include it in the model definition by using Keras's preprocessing layers. \n",
    "- This is the approach that we'll take.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-syndicate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T16:40:54.612102Z",
     "iopub.status.busy": "2021-06-03T16:40:54.611434Z",
     "iopub.status.idle": "2021-06-03T16:40:57.718945Z",
     "shell.execute_reply": "2021-06-03T16:40:57.718267Z"
    },
    "papermill": {
     "duration": 3.117999,
     "end_time": "2021-06-03T16:40:57.719101",
     "exception": false,
     "start_time": "2021-06-03T16:40:54.601102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# , input_shape=[(128, 128, 1)])\n",
    "pretrained_base = VGG16(include_top=False, weights=\"imagenet\")\n",
    "\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Preprocessing\n",
    "    preprocessing.RandomFlip('horizontal'),  # flip left-to-right\n",
    "    preprocessing.RandomContrast(0.5),  # contrast change by up to 50%\n",
    "    # Base\n",
    "    pretrained_base,\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-knowing",
   "metadata": {
    "papermill": {
     "duration": 0.008806,
     "end_time": "2021-06-03T16:40:57.736597",
     "exception": false,
     "start_time": "2021-06-03T16:40:57.727791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-israeli",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T16:40:57.767358Z",
     "iopub.status.busy": "2021-06-03T16:40:57.766322Z",
     "iopub.status.idle": "2021-06-04T00:23:54.734941Z",
     "shell.execute_reply": "2021-06-04T00:23:54.732924Z"
    },
    "papermill": {
     "duration": 27776.991223,
     "end_time": "2021-06-04T00:23:54.735904",
     "exception": false,
     "start_time": "2021-06-03T16:40:57.744681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-playlist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T00:23:54.787658Z",
     "iopub.status.busy": "2021-06-04T00:23:54.777972Z",
     "iopub.status.idle": "2021-06-04T00:23:55.625759Z",
     "shell.execute_reply": "2021-06-04T00:23:55.626560Z"
    },
    "papermill": {
     "duration": 0.873914,
     "end_time": "2021-06-04T00:23:55.626841",
     "exception": false,
     "start_time": "2021-06-04T00:23:54.752927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-entrepreneur",
   "metadata": {},
   "source": [
    "\n",
    "- The training and validation curves in the model from Tutorial 1 diverged fairly quickly, suggesting that it could benefit from some regularization. \n",
    "- The learning curves for this model were able to stay closer together, and we achieved some modest improvement in validation loss and accuracy. \n",
    "- This suggests that the dataset did indeed benefit from the augmentation.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-permission",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-gregory",
   "metadata": {},
   "source": [
    "\n",
    "- https://www.kaggle.com/ryanholbrook/data-augmentation\n",
    "- [Link to dataset](https://www.kaggle.com/ryanholbrook/car-or-truck)\n",
    "- [How to import the pre-trained model]()\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-memphis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27799.27592,
   "end_time": "2021-06-04T00:23:56.995585",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T16:40:37.719665",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
