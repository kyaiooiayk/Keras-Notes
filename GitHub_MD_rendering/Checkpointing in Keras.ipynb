{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Checkpointing in Keras\n",
    "\n",
    "Deep learning models can take hours, days or even weeks to train and if a training run is stopped unexpectedly,\n",
    "you can lose a lot of work. Checkpointing offers a solution.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import python modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Application checkpointing is a fault tolerance technique for long running processes. It is an approach where a \n",
    "snapshot of the state of the system is taken in case of system failure. If there is a problem, not all is lost.\n",
    "The checkpoint may be used directly, or used as the starting point for a new run, picking up where it left off. \n",
    "When training deep learning models, the checkpoint captures the weights of the model. These weights can be used\n",
    "to make predictions as-is, or used as the basis for ongoing training.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint the weights WHEN validation accuracy IMPROVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x14dc6d820>]\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.63230, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.63230 to 0.64008, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.64008\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.64008 to 0.65370, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.65370 to 0.65564, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.65564 to 0.66342, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.66342\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.66342 to 0.67704, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.67704\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.67704\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.67704 to 0.68093, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.68093 to 0.68482, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.68482\n",
      "\n",
      "Epoch 00014: accuracy improved from 0.68482 to 0.69261, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.69261\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.69261 to 0.69650, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.69650\n",
      "\n",
      "Epoch 00018: accuracy improved from 0.69650 to 0.70623, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.70623\n",
      "\n",
      "Epoch 00020: accuracy improved from 0.70623 to 0.71206, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00021: accuracy improved from 0.71206 to 0.71595, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.71595\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.71595\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.71595\n",
      "\n",
      "Epoch 00025: accuracy improved from 0.71595 to 0.72179, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.72179\n",
      "\n",
      "Epoch 00032: accuracy improved from 0.72179 to 0.72374, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.72374\n",
      "\n",
      "Epoch 00034: accuracy improved from 0.72374 to 0.73735, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.73735\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.73735\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.73735\n",
      "\n",
      "Epoch 00038: accuracy improved from 0.73735 to 0.74319, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.74319\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.74319\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.74319\n",
      "\n",
      "Epoch 00042: accuracy improved from 0.74319 to 0.75486, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00052: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00053: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00054: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00056: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00059: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00060: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00061: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00062: accuracy did not improve from 0.75486\n",
      "\n",
      "Epoch 00063: accuracy improved from 0.75486 to 0.75681, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00064: accuracy did not improve from 0.75681\n",
      "\n",
      "Epoch 00065: accuracy improved from 0.75681 to 0.76070, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00067: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00068: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00070: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.76070\n",
      "\n",
      "Epoch 00072: accuracy improved from 0.76070 to 0.76848, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00073: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00075: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00077: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00078: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00079: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00080: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00081: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00082: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00083: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00084: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00085: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00086: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00087: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00088: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00089: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00090: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00091: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00092: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00093: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00094: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00095: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00096: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00097: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00098: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00099: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00100: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00101: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00102: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00103: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00104: accuracy did not improve from 0.76848\n",
      "\n",
      "Epoch 00105: accuracy improved from 0.76848 to 0.77043, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00106: accuracy did not improve from 0.77043\n",
      "\n",
      "Epoch 00107: accuracy improved from 0.77043 to 0.77626, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00108: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00109: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00110: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00111: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00112: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00113: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00114: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00115: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00116: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00117: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00118: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00119: accuracy did not improve from 0.77626\n",
      "\n",
      "Epoch 00120: accuracy improved from 0.77626 to 0.78016, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00121: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00122: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00123: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00124: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00125: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00126: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00127: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00128: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00129: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00130: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00131: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00132: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00133: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00134: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00135: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00136: accuracy did not improve from 0.78016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00137: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00138: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00139: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00140: accuracy did not improve from 0.78016\n",
      "\n",
      "Epoch 00141: accuracy improved from 0.78016 to 0.78210, saving model to ../OUTPUT/weights-best.hdf5\n",
      "\n",
      "Epoch 00142: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00143: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00144: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00145: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00146: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00147: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00148: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00149: accuracy did not improve from 0.78210\n",
      "\n",
      "Epoch 00150: accuracy did not improve from 0.78210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14dcbc6a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"../DATASETS/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer= \"uniform\" , activation= \"sigmoid\" ))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer= \"adam\" , metrics=[ \"accuracy\" ])\n",
    "\n",
    "# checkpoint\n",
    "# OPTION #1 - IF YOU WANT TO NOW WHAT HAPPENS in each step\n",
    "#filepath = \"../OUTPUT/weights-improvement_EPOCH_-{epoch:02d}-_ACURACY_{accuracy:.4f}.hdf5\"\n",
    "# OPTION #2 -  rewriting the same file\n",
    "filepath = \"../OUTPUT/weights-best.hdf5\"\n",
    "\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = \"val_acc\" , verbose=1, save_best_only=True, mode= max )\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor = \"val_acc\" , verbose=1, save_best_only=True )\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = \"accuracy\" , save_weights_only=True, verbose=1, save_best_only=True )\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "print(callbacks_list)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs = 150, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a very simple checkpointing strategy. It may create a lot of unnecessary checkpoint files if the validation \n",
    "accuracy moves up and down over training epochs. Nevertheless, it will ensure that you have a snapshot of the best \n",
    "model discovered during your run.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Saved Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The checkpoint only includes the model weights. It assumes you know the network structure. This too can be serialize\n",
    "to file in JSON or YAML format. In the example below, the model structure is known and the best weights are loaded \n",
    "from the previous experiment, stored in the working directory in the weights.best.hdf5 file. The model is then used\n",
    "to make predictions on the entire dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "accuracy: 75.91%\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer = \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer= \"uniform\" , activation= \"sigmoid\" ))\n",
    "\n",
    "# load weights\n",
    "model.load_weights(\"../OUTPUT/weights-best.hdf5\")\n",
    "\n",
    "# Compile model (required to make predictions)\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer = \"adam\" , metrics=[ \"accuracy\" ])\n",
    "print(\"Created model and loaded weights from file\")\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"../DATASETS/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# estimate accuracy on whole dataset using loaded weights\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://machinelearningmastery.com/check-point-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
